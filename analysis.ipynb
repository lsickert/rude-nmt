{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "This notebook contains some of the experiments that were performed for the Master Thesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from tatoeba import analysis as tatoeba_analysis\n",
    "from rude_nmt import analysis as rude_nmt_analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "Due to the large amount of time needed to generate the translations, they are performed for each direction individually. Run the following merge in order to combine the two datasets into one for the remaining analyses if that has not already been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_data = load_from_disk(\"./data/tatoeba_de_ko_labelled\")\n",
    "de_data = load_from_disk(\"./data/tatoeba_ko_de_labelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = [col for col in ko_data.column_names if col in de_data.column_names]\n",
    "disjunct_de = de_data.remove_columns(column_names=remove_cols)\n",
    "merged_data = concatenate_datasets([ko_data, disjunct_de], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.save_to_disk(\"./data/tatoeba_merged\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset\n",
    "First the dataset is explored to obtain some base level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"./data/tatoeba_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"de_formality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"ko_formality\", ax_annotate_vals=(0.3,2500))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove all ambiguous samples in case this has not been done during the labeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.filter(lambda ex: not (ex[\"de_formality\"] == \"ambiguous\" or ex[\"ko_formality\"] == \"ambiguous\"), num_proc=os.cpu_count())\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_cross_formality_plot(ds, \"ko_formality\", \"de_formality\", exclude_vals=[\"ambiguous\"], form_col_desc=\"Korean formality\", cross_col_desc=\"German formality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analzye the translations\n",
    "As the next step, the quality of the translations is analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"de_formality_nmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"ko_formality_nmt\", ax_annotate_vals=(0.3,2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_ds = ds.filter(lambda ex: ex[\"de_formality_nmt\"] != \"ambiguous\", num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_cross_formality_plot(cross_ds, \"ko_formality_nmt\", \"de_formality_nmt\", form_col_desc=\"Korean formality\", cross_col_desc=\"German formality\", plot_title=\"form_distribution_nmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the comet score has to be upscaled to fit into the same range as BLEU and chrF\n",
    "def upscale_comet(example):\n",
    "    example[\"comet_ko\"] = example[\"comet_ko\"] * 100\n",
    "    example[\"comet_de\"] = example[\"comet_de\"] * 100\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(upscale_comet, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rude_nmt_analysis.plot_translation_metrics(ds, [\"bleu_ko\", \"chrf_ko\", \"comet_ko\"], [\"BLEU\", \"chrF\", \"COMET\"], show=True, plt_name=\"translation_metrics_ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rude_nmt_analysis.plot_translation_metrics(ds, [\"bleu_de\", \"chrf_de\", \"comet_de\"], [\"BLEU\", \"chrF\", \"COMET\"], show=True, plt_name=\"translation_metrics_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rude_nmt_analysis.plot_sankey(ds, \"ko_formality\", \"ko_formality_nmt\", show=True, plt_name=\"sankey_ko_formality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rude_nmt_analysis.plot_sankey(ds, \"de_formality\", \"de_formality_nmt\", show=True, plt_name=\"sankey_de_formality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove all samples with a comet score below 0.4 (40 in this case, since the scores have been upscaled before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.filter(lambda ex: ex[\"comet_ko\"] > 40 and ex[\"comet_de\"] > 40, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"de_formality\", save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba_analysis.get_formality_plot(ds, \"ko_formality\", ax_annotate_vals=(0.3,2500), save=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save COMET filtered dataset to disk for use in the attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk(\"./data/tatoeba_filtered\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "analyze the attributions for the translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally load the filtered dataset from disk\n",
    "ds = load_from_disk(\"./data/tatoeba_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'source': 'Carol, hier ist Vincent. Sag nichts. Hör bloß zu.', 'target': '캐럴, 나야 빈센트 말하지 말고 들어', 'ko_nmt': '캐롤, 여기  Vincent이 있습니다. 말하지 마세요. 그냥 들어보세요.', 'chrf_ko': 10.119, 'bleu_ko': 9.38, 'comet_ko': 76.2, 'upos_tags_source': ['PROPN', 'PUNCT', 'ADV', 'AUX', 'PROPN', 'PUNCT', 'VERB', 'PRON', 'PUNCT', 'VERB', 'ADV', 'ADP', 'PUNCT'], 'pos_tags_source': ['NE', '$,', 'ADV', 'VAFIN', 'NE', '$.', 'VVIMP', 'PIS', '$.', 'VVIMP', 'ADV', 'PTKVZ', '$.'], 'ws_tokens_source': ['Carol', ',', 'hier', 'ist', 'Vincent', '.', 'Sag', 'nichts', '.', 'Hör', 'bloß', 'zu', '.'], 'sent_ids_source': [0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2], 'de_formality': 'underspecified', 'de_formality_map': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'upos_tags_target': ['NOUN', 'PUNCT', 'ADV', 'PROPN', 'VERB', 'CCONJ', 'SCONJ'], 'pos_tags_target': ['ncn', 'sp', 'npp+jca', 'nq', 'pvg+ecx', 'px+ecc', 'pvg+ecs'], 'ws_tokens_target': ['캐럴', ',', '나야', '빈센트', '말하지', '말고', '들어'], 'sent_ids_target': [0, 0, 0, 0, 0, 0, 0], 'upos_tags_ko_nmt': ['NOUN', 'PUNCT', 'PRON', 'SPACE', 'X', 'ADJ', 'PUNCT', 'VERB', 'AUX', 'PUNCT', 'ADV', 'VERB', 'PUNCT'], 'pos_tags_ko_nmt': ['ncn', 'sp', 'npd', '_SP', 'f+jcs', 'paa+ef', 'sf', 'pvg+ecx', 'px+ef', 'sf', 'mag', 'pvg+ef', 'sf'], 'ws_tokens_ko_nmt': ['캐롤', ',', '여기', ' ', 'Vincent이', '있습니다', '.', '말하지', '마세요', '.', '그냥', '들어보세요', '.'], 'sent_ids_ko_nmt': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2], 'ko_formality': 'haeche', 'ko_formality_map': [0, 0, 0, 0, 0, 0, 1], 'ko_formality_nmt': 'ambiguous', 'ko_formality_map_nmt': [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0], 'de_nmt': 'Carol, don\\'t say \"Naya Vincent\"!', 'chrf_de': 24.497, 'bleu_de': 6.766, 'comet_de': 41.699999999999996, 'upos_tags_de_nmt': ['PROPN', 'PUNCT', 'X', 'X', 'PUNCT', 'PROPN', 'PROPN', 'PUNCT', 'PUNCT'], 'pos_tags_de_nmt': ['NE', '$,', 'FM', 'FM', '$(', 'NE', 'NE', '$(', '$.'], 'ws_tokens_de_nmt': ['Carol', ',', \"don't\", 'say', '\"', 'Naya', 'Vincent', '\"', '!'], 'sent_ids_de_nmt': [0, 0, 0, 0, 0, 0, 0, 0, 1], 'de_formality_nmt': 'underspecified', 'de_formality_map_nmt': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inseq\n",
    "from transformers import (MBartForConditionalGeneration, MBart50TokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"de_DE\", tgt_lang=\"ko_KR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_model = inseq.load_model(model, \"input_x_gradient\", tokenizer=de_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attributing with input_x_gradient...: 100%|██████████| 20/20 [00:11<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/><b>0th instance:</b><br/>\n",
       "<html>\n",
       "<div id=\"igfywirkxlggogpxkfzn_viz_container\">\n",
       "    <div id=\"igfywirkxlggogpxkfzn_content\" style=\"padding:15px;border-style:solid;margin:5px;\">\n",
       "        <div id = \"igfywirkxlggogpxkfzn_saliency_plot_container\" class=\"igfywirkxlggogpxkfzn_viz_container\" style=\"display:block\">\n",
       "            \n",
       "<div id=\"qjjfgyqpesejzqorvufa_saliency_plot\" class=\"qjjfgyqpesejzqorvufa_viz_content\">\n",
       "    <div style=\"margin:5px;font-family:sans-serif;font-weight:bold;\">\n",
       "        <span style=\"font-size: 20px;\">Source Saliency Heatmap</span>\n",
       "        <br>\n",
       "        x: Generated tokens, y: Attributed tokens\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" cellpadding=\"5\" cellspacing=\"5\"\n",
       "    style=\"overflow-x:scroll;display:block;\">\n",
       "    <tr><th></th>\n",
       "<th>ko_KR</th><th>▁캐롤,</th><th>▁여기</th><th>▁Vincent이</th><th>▁있습니다.</th><th>▁말하지</th><th>▁마세요.</th><th>▁그냥</th><th>▁들어보세요.</th><th>&lt;/s&gt;</th></tr><tr><th>de_DE</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.22749059219647458)\">0.102</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.071</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.12501485442661908)\">0.058</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.069</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.071</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.13289760348583876)\">0.059</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14078035254505847)\">0.064</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.12501485442661908)\">0.058</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14078035254505847)\">0.063</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.29843533372945136)\">0.13</th></tr><tr><th>▁Carol,</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.4797385620915033)\">0.212</th><th style=\"background:rgba(255.0, 13.0, 87.0, 1.0)\">0.438</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.22749059219647458)\">0.101</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.20384234501881549)\">0.089</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.22749059219647458)\">0.101</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1171321053673995)\">0.053</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14866310160427795)\">0.066</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.09348385818974037)\">0.042</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.09348385818974037)\">0.043</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2590215884333532)\">0.114</th></tr><tr><th>▁hier</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.08560110913052081)\">0.041</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.08560110913052081)\">0.041</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.22749059219647458)\">0.102</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.13289760348583876)\">0.062</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.07</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.05407011289364243)\">0.025</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.05407011289364243)\">0.026</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.030421865715983164)\">0.017</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.03830461477520289)\">0.019</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th></tr><tr><th>▁ist</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.08560110913052081)\">0.039</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14866310160427795)\">0.066</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10924935630817992)\">0.049</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14078035254505847)\">0.064</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.04618736383442265)\">0.024</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.06195286195286207)\">0.029</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.030421865715983164)\">0.017</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.03830461477520289)\">0.018</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.06195286195286207)\">0.029</th></tr><tr><th>▁Vincent.</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.36149732620320857)\">0.159</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.39302832244008706)\">0.175</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.9211725094078035)\">0.401</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.9605862547039017)\">0.421</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.4560903149138443)\">0.199</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2117250940780353)\">0.095</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2117250940780353)\">0.093</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1171321053673995)\">0.054</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10924935630817992)\">0.051</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.32208358090711037)\">0.143</th></tr><tr><th>▁Sag</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1959595959595959)\">0.086</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1171321053673995)\">0.052</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.072</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.069</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.29843533372945136)\">0.132</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.5979797979797981)\">0.263</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.4087938205585263)\">0.178</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.072</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2826698356110118)\">0.125</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1880768469003763)\">0.085</th></tr><tr><th>▁nichts.</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14078035254505847)\">0.062</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1171321053673995)\">0.052</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.047</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.17231134878193693)\">0.077</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.3693800752624282)\">0.163</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.29055258467023165)\">0.127</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10924935630817992)\">0.051</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.045</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.13289760348583876)\">0.06</th></tr><tr><th>▁Hör</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14866310160427795)\">0.068</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.035</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.09348385818974037)\">0.043</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1959595959595959)\">0.086</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1959595959595959)\">0.087</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.3299663299663301)\">0.146</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.44820756585462457)\">0.198</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.5664488017429193)\">0.25</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.24325609031491383)\">0.107</th></tr><tr><th>▁bloß</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1959595959595959)\">0.087</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.09348385818974037)\">0.044</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.045</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.048</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.24325609031491383)\">0.106</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2826698356110118)\">0.125</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.3693800752624282)\">0.161</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.77928302634185)\">0.341</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.36149732620320857)\">0.16</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.29055258467023165)\">0.127</th></tr><tr><th>▁zu.</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.18019409784115661)\">0.081</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.035</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.06195286195286207)\">0.03</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.1171321053673995)\">0.053</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.12501485442661908)\">0.057</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.13289760348583876)\">0.06</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.15654585066349747)\">0.069</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2590215884333532)\">0.114</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.4087938205585263)\">0.179</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.2747870865517925)\">0.122</th></tr><tr><th>&lt;/s&gt;</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.14866310160427795)\">0.066</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.06983561101208159)\">0.033</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10924935630817992)\">0.051</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.07771836007130124)\">0.036</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.046</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.08560110913052081)\">0.04</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.08560110913052081)\">0.038</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.047</th><th style=\"background:rgba(255.0, 13.0, 87.0, 0.10136660724896006)\">0.046</th></tr><tr style=\"outline: thin solid\"><th><b>probability</b></th><th>0.0</th><th>0.08</th><th>0.149</th><th>0.034</th><th>0.325</th><th>0.046</th><th>0.261</th><th>0.311</th><th>0.082</th><th><b>0.872</b></th></table>\n",
       "</div>\n",
       "\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = attr_model.attribute(\n",
    "    input_texts=ds[0][\"source\"],\n",
    "    generated_texts=ds[0][\"ko_nmt\"],\n",
    "    attribute_target=False,\n",
    "    batch_size=5,\n",
    "    step_scores=[\"probability\"]\n",
    ")\n",
    "out = out.aggregate(aggregator=inseq.data.aggregator.AggregatorPipeline([inseq.data.aggregator.SubwordAggregator]))\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_model2 = inseq.load_model(\"facebook/mbart-large-50-many-to-many-mmt\", \"input_x_gradient\", tokenizer_kwargs={\"src_lang\": \"de_DE\", \"tgt_lang\": \"ko_KR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attributing with input_x_gradient...: 100%|██████████| 20/20 [00:11<00:00,  1.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.43840715289115906,\n",
       "  0.04073164984583855,\n",
       "  0.03927171230316162,\n",
       "  0.17463932931423187,\n",
       "  0.05206599459052086,\n",
       "  0.036157362163066864,\n",
       "  0.035129863768815994,\n",
       "  0.04412499815225601,\n",
       "  0.03491465747356415],\n",
       " [0.10082988440990448,\n",
       "  0.10249965637922287,\n",
       "  0.06634380668401718,\n",
       "  0.40117913484573364,\n",
       "  0.0718628540635109,\n",
       "  0.05241023376584053,\n",
       "  0.03628076612949371,\n",
       "  0.04467998072504997,\n",
       "  0.02951953560113907],\n",
       " [0.08911564201116562,\n",
       "  0.06162300333380699,\n",
       "  0.04919227212667465,\n",
       "  0.42056745290756226,\n",
       "  0.06929496675729752,\n",
       "  0.04737542197108269,\n",
       "  0.04316408932209015,\n",
       "  0.047713398933410645,\n",
       "  0.05252497270703316],\n",
       " [0.10068227350711823,\n",
       "  0.07031651586294174,\n",
       "  0.06434743851423264,\n",
       "  0.19930046796798706,\n",
       "  0.13165660202503204,\n",
       "  0.0774613693356514,\n",
       "  0.08638675510883331,\n",
       "  0.10635272413492203,\n",
       "  0.05673668161034584],\n",
       " [0.05263480916619301,\n",
       "  0.02512262761592865,\n",
       "  0.023653635755181313,\n",
       "  0.0949077233672142,\n",
       "  0.2626975476741791,\n",
       "  0.16323798894882202,\n",
       "  0.08677950501441956,\n",
       "  0.12518410384655,\n",
       "  0.06048725172877312],\n",
       " [0.06647954881191254,\n",
       "  0.026017818599939346,\n",
       "  0.029083071276545525,\n",
       "  0.09279634058475494,\n",
       "  0.17844828963279724,\n",
       "  0.1269061267375946,\n",
       "  0.14574775099754333,\n",
       "  0.16138264536857605,\n",
       "  0.06938355416059494],\n",
       " [0.041647978127002716,\n",
       "  0.016840139403939247,\n",
       "  0.01673269271850586,\n",
       "  0.05374853312969208,\n",
       "  0.0717572346329689,\n",
       "  0.05056960508227348,\n",
       "  0.19755971431732178,\n",
       "  0.34125271439552307,\n",
       "  0.1139526441693306],\n",
       " [0.0425201915204525,\n",
       "  0.019289325922727585,\n",
       "  0.01804172806441784,\n",
       "  0.05094461143016815,\n",
       "  0.12458448112010956,\n",
       "  0.04529576748609543,\n",
       "  0.2497047781944275,\n",
       "  0.16039347648620605,\n",
       "  0.17922860383987427]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#    generated_texts=ds[0:10][\"ko_nmt\"],\n",
    "#    layers=(0,-1),\n",
    "#    heads=(0,-1),\n",
    "out = attr_model2.attribute(\n",
    "    input_texts=ds[0][\"source\"],\n",
    "    generated_texts=ds[0][\"ko_nmt\"],\n",
    "    attribute_target=False,\n",
    "    batch_size=5,\n",
    "    step_scores=[\"probability\"]\n",
    ")\n",
    "out = out.aggregate(aggregator=inseq.data.aggregator.AggregatorPipeline([inseq.data.aggregator.SubwordAggregator, inseq.data.aggregator.SequenceAttributionAggregator]))\n",
    "out.sequence_attributions[0].source_attributions[1:-1].T[1:-1].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizerFast, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", output_attentions=True)\n",
    "nllb_tokenizer = NllbTokenizerFast.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"deu_Latn\", tgt_lang=\"kor_Hang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllb_model = inseq.load_model(nllb_model, \"attention\", tokenizer=nllb_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nllb_model.attribute(\n",
    "    input_texts=ds[0:10][\"source\"],\n",
    "    generation_args={\"forced_bos_token_id\": nllb_tokenizer.lang_code_to_id[\"kor_Hang\"]},\n",
    "    attribute_target=False,\n",
    "    layers=(0,-1),\n",
    "    heads=(0,-1),\n",
    "    batch_size=5\n",
    ")\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Helsinki-NLP/opus-mt-en-de\"\n",
    "model = inseq.load_model(\"gpt2\", \"attention\")\n",
    "out = model.attribute(\n",
    "    \"translate this to german: hello world\",\n",
    "    layers=(0,-1),\n",
    "    heads=(0,-1),\n",
    ")\n",
    "out.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
